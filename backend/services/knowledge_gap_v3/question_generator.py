"""
Stage 4: LLM Question Generation
================================

Uses GPT-4 to generate perfect, contextual questions from detected gaps.
Instead of template filling, this generates natural language questions
tailored to the specific context.
"""

import json
import logging
import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime

from services.openai_client import get_openai_client

from .gap_analyzers import Gap, GapType, GapSeverity
from .knowledge_graph import KnowledgeGraph, Entity, EntityType

logger = logging.getLogger(__name__)


# =============================================================================
# DATA STRUCTURES
# =============================================================================

@dataclass
class GeneratedQuestion:
    """A rich question object generated by LLM"""
    id: str
    gap_id: str
    primary_question: str
    sub_questions: List[str] = field(default_factory=list)
    suggested_respondent: Optional[str] = None
    respondent_reason: Optional[str] = None
    answer_format_suggestion: Optional[str] = None
    estimated_effort: Optional[str] = None
    priority_reasoning: str = ""
    business_impact: str = ""
    context_summary: str = ""
    category: str = "general"
    confidence: float = 0.8
    generated_at: str = field(default_factory=lambda: datetime.utcnow().isoformat())

    def to_dict(self) -> Dict:
        return {
            "id": self.id,
            "gap_id": self.gap_id,
            "primary_question": self.primary_question,
            "sub_questions": self.sub_questions,
            "suggested_respondent": self.suggested_respondent,
            "respondent_reason": self.respondent_reason,
            "answer_format_suggestion": self.answer_format_suggestion,
            "estimated_effort": self.estimated_effort,
            "priority_reasoning": self.priority_reasoning,
            "business_impact": self.business_impact,
            "context_summary": self.context_summary,
            "category": self.category,
            "confidence": self.confidence,
            "generated_at": self.generated_at
        }


# =============================================================================
# QUESTION GENERATION PROMPTS
# =============================================================================

QUESTION_GENERATION_SYSTEM_PROMPT = """You are an expert knowledge management consultant specializing in organizational knowledge transfer. Your task is to generate perfect questions that will help fill knowledge gaps in an organization.

Your questions must be:
1. SPECIFIC - Not generic, tailored to the exact context provided
2. GROUNDED - Based on the evidence and documents mentioned
3. ACTIONABLE - The answer should result in documented knowledge
4. ANSWERABLE - Someone in the organization can answer this
5. VALUABLE - The answer provides critical organizational context

You understand that the goal is KNOWLEDGE TRANSFER - capturing tacit knowledge before it's lost.

Output valid JSON matching the specified schema."""


QUESTION_GENERATION_PROMPT = """Generate questions to fill this knowledge gap.

GAP TYPE: {gap_type}
GAP SEVERITY: {severity}
GAP TITLE: {title}
GAP DESCRIPTION: {description}

EVIDENCE:
{evidence}

AFFECTED ENTITIES:
{affected_entities}

ORGANIZATIONAL CONTEXT:
{org_context}

---

Generate a JSON response with:

{{
  "primary_question": "The main question that addresses this gap. Should be specific and contextual.",

  "sub_questions": [
    "Follow-up question 1 that digs deeper",
    "Follow-up question 2 for completeness",
    "Follow-up question 3 if relevant"
  ],

  "suggested_respondent": "Name or role of person best suited to answer",
  "respondent_reason": "Why this person/role is the right respondent",

  "answer_format_suggestion": "What form should the answer take? (e.g., 'Document the process steps', 'Create a runbook', 'Add to architecture diagram')",

  "estimated_effort": "How long should answering take? (e.g., '30 minutes', '1-2 hours', 'Half day')",

  "priority_reasoning": "Why is this gap important to fill? What's the risk of not filling it?",

  "business_impact": "What is the business impact if this knowledge is lost?",

  "context_summary": "Brief summary of the context for someone seeing this question",

  "category": "One of: decision, process, technical, relationship, ownership, context, risk"
}}

Make the primary question natural and conversational, as if a thoughtful colleague is asking.
Sub-questions should cover different angles of the same gap.

Return ONLY valid JSON."""


# =============================================================================
# GAP-SPECIFIC PROMPT TEMPLATES
# =============================================================================

GAP_CONTEXT_TEMPLATES = {
    GapType.CRITICAL_BUS_FACTOR: """
This is a CRITICAL bus factor risk. A single person ({metadata.get('owner', 'unknown')}) owns
{metadata.get('owned_item', 'a critical system')} with no documented backup.

The business risk is severe: if this person leaves or is unavailable, critical knowledge is lost.

Focus questions on:
- What knowledge exists only in this person's head?
- Who could be trained as backup?
- What documentation needs to be created?
""",

    GapType.KNOWLEDGE_CONCENTRATION: """
One person ({metadata.get('owner', 'unknown')}) is responsible for {metadata.get('owned_count', 'multiple')}
different systems/processes. This concentration of knowledge is a risk.

Items owned: {metadata.get('owned_items', [])}

Focus questions on:
- How to distribute this knowledge?
- What cross-training is needed?
- What's the priority order for documentation?
""",

    GapType.MISSING_RATIONALE: """
A decision was made ({metadata.get('decision', 'unknown')}) but the WHY is not documented.
Current rationale quality: {metadata.get('why_quality', 'missing')}

Focus questions on:
- What problem was being solved?
- What constraints existed at the time?
- What trade-offs were accepted?
""",

    GapType.NO_ALTERNATIVES_DOCUMENTED: """
A decision was made ({metadata.get('decision', 'unknown')}) but alternatives weren't documented.

Focus questions on:
- What other options were considered?
- Why were they rejected?
- Under what conditions should this be revisited?
""",

    GapType.INCOMPLETE_CRITICAL_PROCESS: """
A {metadata.get('criticality', 'critical')} process ({metadata.get('process', 'unknown')})
is only {metadata.get('completeness_score', 0)*100:.0f}% documented.

Missing: {metadata.get('missing', [])}

Focus questions on:
- What are the actual steps?
- What can go wrong?
- Who should be contacted if issues arise?
""",

    GapType.KNOWLEDGE_LOCKED_IN_PERSON: """
Multiple documents reference {metadata.get('person', 'someone')} as the knowledge holder for:
{metadata.get('topics', [])}

This is tribal knowledge that needs to be documented.

Focus questions on:
- What does this person know that isn't written down?
- What questions do people usually ask them?
- What would be lost if they left?
""",

    GapType.UNKNOWN_FAILURE_CASCADE: """
{metadata.get('source', 'A system')} depends on {metadata.get('target', 'another system')},
but what happens when it fails is undocumented.

Focus questions on:
- What exactly fails when the dependency is unavailable?
- What's the recovery procedure?
- Who needs to be notified?
"""
}


# =============================================================================
# QUESTION GENERATOR
# =============================================================================

class QuestionGenerator:
    """
    Generates rich, contextual questions from gaps using Azure OpenAI.
    """

    def __init__(self, graph: KnowledgeGraph, model: str = None):
        self.graph = graph
        self.client = get_openai_client()
        self.model = model or self.client.get_chat_model()
        self._question_counter = 0
        logger.info(f"[QuestionGenerator] Initialized with model: {self.model}")

    def generate_questions(
        self,
        gaps: List[Gap],
        org_context: Optional[Dict[str, Any]] = None
    ) -> List[GeneratedQuestion]:
        """
        Generate questions for a list of gaps.

        Args:
            gaps: List of detected gaps
            org_context: Optional organizational context (team size, industry, etc.)

        Returns:
            List of generated questions
        """
        logger.info(f"[QuestionGenerator] Generating questions for {len(gaps)} gaps...")

        questions = []
        org_context = org_context or {}

        for gap in gaps:
            try:
                question = self._generate_for_gap(gap, org_context)
                if question:
                    questions.append(question)
            except Exception as e:
                logger.error(f"[QuestionGenerator] Error generating for gap {gap.id}: {e}")
                # Create fallback question
                questions.append(self._create_fallback_question(gap))

        logger.info(f"[QuestionGenerator] Generated {len(questions)} questions")
        return questions

    def _generate_for_gap(
        self,
        gap: Gap,
        org_context: Dict[str, Any]
    ) -> Optional[GeneratedQuestion]:
        """Generate question for a single gap"""
        # Get entity details for context
        entity_details = self._get_entity_details(gap.affected_entities)

        # Get gap-specific context
        gap_context = self._get_gap_context(gap)

        # Build the prompt
        evidence_str = "\n".join(f"- {e}" for e in gap.evidence[:5]) if gap.evidence else "No specific evidence"

        entity_str = "\n".join(
            f"- {e['name']} ({e['type']}): {e.get('description', 'No description')}"
            for e in entity_details
        ) if entity_details else "No specific entities"

        org_context_str = json.dumps(org_context, indent=2) if org_context else "No organizational context provided"

        # Call GPT-4
        response = self.client.chat_completion(
            messages=[
                {"role": "system", "content": QUESTION_GENERATION_SYSTEM_PROMPT},
                {"role": "user", "content": QUESTION_GENERATION_PROMPT.format(
                    gap_type=gap.gap_type.value,
                    severity=gap.severity.value,
                    title=gap.title,
                    description=gap.description + "\n\n" + gap_context,
                    evidence=evidence_str,
                    affected_entities=entity_str,
                    org_context=org_context_str
                )}
            ],
            temperature=0.7,  # Some creativity for natural questions
            max_tokens=2000,
            response_format={"type": "json_object"}
        )

        # Parse response
        raw_json = response.choices[0].message.content
        data = json.loads(raw_json)

        self._question_counter += 1

        return GeneratedQuestion(
            id=f"Q_{gap.id}_{self._question_counter}",
            gap_id=gap.id,
            primary_question=data.get("primary_question", "Question generation failed"),
            sub_questions=data.get("sub_questions", []),
            suggested_respondent=data.get("suggested_respondent") or gap.suggested_respondent,
            respondent_reason=data.get("respondent_reason"),
            answer_format_suggestion=data.get("answer_format_suggestion"),
            estimated_effort=data.get("estimated_effort"),
            priority_reasoning=data.get("priority_reasoning", ""),
            business_impact=data.get("business_impact", ""),
            context_summary=data.get("context_summary", gap.description[:200]),
            category=data.get("category", self._infer_category(gap)),
            confidence=gap.confidence
        )

    def _get_entity_details(self, entity_ids: List[str]) -> List[Dict]:
        """Get details for affected entities"""
        details = []
        for eid in entity_ids:
            entity = self.graph.get_entity(eid)
            if entity:
                details.append({
                    "name": entity.name,
                    "type": entity.entity_type.value,
                    "description": entity.description,
                    "role": entity.role,
                    "source_count": len(entity.source_docs)
                })
        return details

    def _get_gap_context(self, gap: Gap) -> str:
        """Get gap-type specific context"""
        template = GAP_CONTEXT_TEMPLATES.get(gap.gap_type)
        if template:
            try:
                return template.format(metadata=gap.metadata)
            except:
                return template
        return ""

    def _infer_category(self, gap: Gap) -> str:
        """Infer category from gap type"""
        category_map = {
            GapType.CRITICAL_BUS_FACTOR: "ownership",
            GapType.KNOWLEDGE_CONCENTRATION: "ownership",
            GapType.NO_BACKUP_OWNER: "ownership",
            GapType.MISSING_RATIONALE: "decision",
            GapType.NO_ALTERNATIVES_DOCUMENTED: "decision",
            GapType.UNCLEAR_DECISION_MAKER: "decision",
            GapType.STALE_DECISION: "decision",
            GapType.HIGH_STAKES_UNDOCUMENTED: "decision",
            GapType.INCOMPLETE_CRITICAL_PROCESS: "process",
            GapType.MISSING_EDGE_CASES: "process",
            GapType.MISSING_FAILURE_HANDLING: "process",
            GapType.UNVERIFIED_PROCESS: "process",
            GapType.UNDOCUMENTED_STEPS: "process",
            GapType.KNOWLEDGE_LOCKED_IN_PERSON: "context",
            GapType.IMPLICIT_EXPERTISE: "context",
            GapType.UNDOCUMENTED_DEPENDENCY: "technical",
            GapType.UNKNOWN_FAILURE_CASCADE: "technical",
            GapType.CIRCULAR_DEPENDENCY: "technical",
            GapType.STALE_DOCUMENTATION: "context",
            GapType.VAGUE_FUTURE_REFERENCE: "context",
            GapType.UNTRACKED_CHANGE: "context",
            GapType.NUMERIC_CONTRADICTION: "risk",
            GapType.FACTUAL_CONTRADICTION: "risk",
            GapType.STATUS_CONTRADICTION: "risk",
            GapType.UNDEFINED_TERM: "context",
            GapType.ASSUMED_CONTEXT: "context",
            GapType.MISSING_PREREQUISITE: "context",
        }
        return category_map.get(gap.gap_type, "general")

    def _create_fallback_question(self, gap: Gap) -> GeneratedQuestion:
        """Create a simple fallback question if LLM fails"""
        self._question_counter += 1

        return GeneratedQuestion(
            id=f"Q_{gap.id}_{self._question_counter}",
            gap_id=gap.id,
            primary_question=f"Can you help fill this knowledge gap: {gap.title}?",
            sub_questions=[
                "What context is missing here?",
                "Who would know more about this?",
                "Where should this be documented?"
            ],
            suggested_respondent=gap.suggested_respondent,
            priority_reasoning=f"This is a {gap.severity.value} severity gap.",
            business_impact="Knowledge loss risk if not addressed.",
            context_summary=gap.description[:200],
            category=self._infer_category(gap),
            confidence=0.5  # Lower confidence for fallback
        )

    def generate_batch(
        self,
        gaps: List[Gap],
        org_context: Optional[Dict[str, Any]] = None,
        batch_size: int = 10
    ) -> List[GeneratedQuestion]:
        """
        Generate questions in batches for efficiency.
        """
        all_questions = []

        for i in range(0, len(gaps), batch_size):
            batch = gaps[i:i + batch_size]
            questions = self.generate_questions(batch, org_context)
            all_questions.extend(questions)

            logger.info(f"[QuestionGenerator] Processed batch {i//batch_size + 1}, "
                       f"total questions: {len(all_questions)}")

        return all_questions
